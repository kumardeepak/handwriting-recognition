{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure you have \"data\" directory in parallel to \"notebooks\". Create \"input\" directory under\n",
    "# \"data\" directory and copy sample image file.\n",
    "# application creates \"output\" programmatically.\n",
    "# ----+/notebooks\n",
    "# ----+/data\n",
    "# ----------+/input\n",
    "\n",
    "base_dir                   = '/Users/kd/Workspace/python/github/handwriting-recognition'\n",
    "data_dir                   = 'data'\n",
    "input_data_dir             = 'input'\n",
    "output_data_dir            = 'output'\n",
    "\n",
    "output_extracted_tables_dir  = 'tables'\n",
    "output_extracted_boxes_dir   = 'boxes'\n",
    "output_extracted_letters_dir = 'letters'\n",
    "\n",
    "input_filename               = 'sample_input_02.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function\n",
    "def create_directory(path):\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "        return True\n",
    "    except FileExistsError as fe_error:\n",
    "        return True\n",
    "    except OSError as error:\n",
    "        print(error)\n",
    "    return False\n",
    "\n",
    "# read files present in a directory\n",
    "def read_directory_files(path, pattern='*'):\n",
    "    files = [f for f in glob.glob(os.path.join(path, pattern))]\n",
    "    return files\n",
    "\n",
    "def get_subdirectories(path):\n",
    "    return [f.path for f in os.scandir(output_boxes_dir) if f.is_dir() ] \n",
    "\n",
    "def show_img(img):\n",
    "    plt.axis('off')\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect horizontal and vertical lines in the cropped images and extract boxes\n",
    "def smoothen_out_image(image):\n",
    "    edges  = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 3, -2)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    edges  = cv2.dilate(edges, kernel)\n",
    "    smooth = np.copy(image)\n",
    "    smooth = cv2.blur(smooth, (2, 2))\n",
    "    (rows, cols) = np.where(edges != 0)\n",
    "    image[rows, cols] = smooth[rows, cols]\n",
    "    return image\n",
    "\n",
    "def combine_image(vertical_img, horizontal_img):\n",
    "    alpha  = 0.5\n",
    "    beta   = 1.0 - alpha\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    # This function helps to add two image with specific weight parameter to get a third image as summation of two image.\n",
    "    img_final = cv2.addWeighted(vertical_img, alpha, horizontal_img, beta, 0.0)\n",
    "    img_final = cv2.erode(~img_final, kernel, iterations=2)\n",
    "    (thresh, img_final) = cv2.threshold(img_final, 128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    return img_final\n",
    "\n",
    "def extract_boxes_from_image(filepath):\n",
    "    src_img      = cv2.imread(filepath, cv2.IMREAD_COLOR)\n",
    "    gray_img     = src_img\n",
    "    if len(src_img.shape) == 3:\n",
    "        gray_img = cv2.cvtColor(src_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    gray_img = cv2.bitwise_not(gray_img)\n",
    "    bw_img   = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15, -2)\n",
    "    \n",
    "    horizontal_img = np.copy(bw_img)\n",
    "    vertical_img   = np.copy(bw_img)\n",
    "    \n",
    "    cols = horizontal_img.shape[1]\n",
    "    horizontal_size = cols // 30\n",
    "    horizontalStructure = cv2.getStructuringElement(cv2.MORPH_RECT, (horizontal_size, 1))\n",
    "    horizontal_img = cv2.erode(horizontal_img, horizontalStructure)\n",
    "    horizontal_img = cv2.dilate(horizontal_img, horizontalStructure)\n",
    "    \n",
    "    rows = vertical_img.shape[0]\n",
    "    vertical_size = rows // 30\n",
    "    verticalStructure = cv2.getStructuringElement(cv2.MORPH_RECT, (1, vertical_size))\n",
    "    vertical_img = cv2.erode(vertical_img, verticalStructure)\n",
    "    vertical_img = cv2.dilate(vertical_img, verticalStructure)\n",
    "    \n",
    "    horizontal_img = smoothen_out_image(horizontal_img)\n",
    "    vertical_img   = smoothen_out_image(vertical_img)\n",
    "    \n",
    "    img_final      = combine_image(vertical_img, horizontal_img)\n",
    "    return src_img, img_final\n",
    "\n",
    "def sort_contours(cnts, method=\"left-to-right\"):\n",
    "    # initialize the reverse flag and sort index\n",
    "    reverse = False\n",
    "    i = 0\n",
    "\n",
    "    # handle if we need to sort in reverse\n",
    "    if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "        reverse = True\n",
    "\n",
    "    # handle if we are sorting against the y-coordinate rather than\n",
    "    # the x-coordinate of the bounding box\n",
    "    if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "        i = 1\n",
    "\n",
    "    # construct the list of bounding boxes and sort them from top to\n",
    "    # bottom\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "        key=lambda b:b[1][i], reverse=reverse))\n",
    "\n",
    "    # return the list of sorted contours and bounding boxes\n",
    "    return (cnts, boundingBoxes)\n",
    "\n",
    "\n",
    "# resize the image by joining the image\n",
    "def resize_image(img, size=(28,28)):\n",
    "    h, w = img.shape[:2]\n",
    "    if h == w: \n",
    "        return cv2.resize(img, size, cv2.INTER_AREA)\n",
    "    dif = h if h > w else w\n",
    "    interpolation = cv2.INTER_AREA if dif > (size[0]+size[1])//2 else cv2.INTER_CUBIC\n",
    "    x_pos = (dif - w)//2\n",
    "    y_pos = (dif - h)//2\n",
    "\n",
    "    if len(img.shape) == 2:\n",
    "        mask = np.zeros((dif, dif), dtype=img.dtype)\n",
    "        mask[y_pos:y_pos+h, x_pos:x_pos+w] = img[:h, :w]\n",
    "    else:\n",
    "        mask = np.zeros((dif, dif, c), dtype=img.dtype)\n",
    "        mask[y_pos:y_pos+h, x_pos:x_pos+w, :] = img[:h, :w, :]\n",
    "\n",
    "    return cv2.resize(mask, size, interpolation)\n",
    "\n",
    "# return b/w images\n",
    "def get_gray_and_bw_image(filepath):\n",
    "    gray_img = cv2.imread(filepath, 0)\n",
    "    gray_img = cv2.bitwise_not(gray_img)\n",
    "    #bw_img   = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15, -2)\n",
    "    bw_img   = cv2.adaptiveThreshold(gray_img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,15,-2)\n",
    "    return gray_img, bw_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract table from the image\n",
    "def extract_tables(filepath, output_dir):\n",
    "    image, image_processed = extract_boxes_from_image(filepath)\n",
    "    _, contours, hierarchy = cv2.findContours(image_processed, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    (contours, boundingBoxes) = sort_contours(contours, method='top-to-bottom')\n",
    "\n",
    "    cont_ind = 0\n",
    "    count = 0\n",
    "    for index, contour in enumerate(contours):\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if (w*h > 300000) and (w*h < 800000):\n",
    "            filename = os.path.join(output_dir, str(int(cont_ind/len(contours))) + \"_\" + str(int(cont_ind%len(contours))) + \"_\" + os.path.basename(img_filename))\n",
    "            crop_img = image[y:y+h, x:x+w]\n",
    "            cv2.imwrite(filename, crop_img)\n",
    "            cont_ind = cont_ind + 1\n",
    "            count    = count + 1\n",
    "    print(\"found (%d) tables in [%s]\" % (count, os.path.basename(filepath)))\n",
    "    \n",
    "    \n",
    "# extract table boxes from table\n",
    "def extract_table_boxes(filepath, output_dir):\n",
    "    image, image_processed = extract_boxes_from_image(filepath)\n",
    "    # Find contours for image, which will detect all the boxes\n",
    "    _, contours, hierarchy = cv2.findContours(image_processed, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Sort all the contours by top to bottom.\n",
    "    (contours, boundingBoxes) = sort_contours(contours, method='top-to-bottom')\n",
    "    \n",
    "    cont_ind = 0\n",
    "    count = 0\n",
    "    for index, contour in enumerate(contours):\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if (w > 80 and h > 20) and (w*h < 100000):\n",
    "            filename = os.path.join(output_dir, str(int(cont_ind/5))+\"_\"+str(int(cont_ind%5))+\"_\"+os.path.basename(filepath))\n",
    "            crop_img = image[y:y+h, x:x+w]\n",
    "            cv2.imwrite(filename, crop_img)\n",
    "            cont_ind = cont_ind + 1\n",
    "            count    = count + 1\n",
    "    print(\"found (%d) boxes in [%s]\" % (count, os.path.basename(filepath)))\n",
    "\n",
    "# let's extract characters from the detected table box\n",
    "def extract_box_letters(filepath, output_dir):    \n",
    "    gray_img, bw_img = get_gray_and_bw_image(filepath)\n",
    "    # find contours and get the external one\n",
    "    _, contours, hier = cv2.findContours(bw_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Sort all the contours by top to bottom.\n",
    "    (contours, boundingBoxes) = sort_contours(contours, method='left-to-right')\n",
    "        \n",
    "    cont_ind = 0\n",
    "    count = 0\n",
    "    for index, contour in enumerate(contours):\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if h > 5 and w < 50:\n",
    "            filename = os.path.join(output_dir, str(int(cont_ind/len(contours)))+\"_\"+str(int(cont_ind%len(contours)))+\"_\"+os.path.basename(filepath))\n",
    "            crop_img = gray_img[y:y+h, x:x+w]\n",
    "            crop_img = resize_image(crop_img)\n",
    "            cv2.imwrite(filename, crop_img)\n",
    "            cont_ind = cont_ind + 1\n",
    "            count    = count + 1\n",
    "    print(\"found (%d) letters in [%s]\" % (count, os.path.basename(filepath)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input filename : [/Users/kd/Workspace/python/github/handwriting-recognition/data/input/sample_input_02.jpg]\n",
      "processing dir: [/Users/kd/Workspace/python/github/handwriting-recognition/data/output/sample_input_02]\n",
      "tables dir: [/Users/kd/Workspace/python/github/handwriting-recognition/data/output/sample_input_02/tables]\n",
      "boxes dir: [/Users/kd/Workspace/python/github/handwriting-recognition/data/output/sample_input_02/boxes]\n",
      "letters: [/Users/kd/Workspace/python/github/handwriting-recognition/data/output/sample_input_02/letters]\n"
     ]
    }
   ],
   "source": [
    "# program initialization \n",
    "img_filename    = os.path.join(base_dir, data_dir, input_data_dir, input_filename)\n",
    "print(\"input filename : [%s]\" % (img_filename))\n",
    "\n",
    "processing_basedir  = os.path.join(base_dir, data_dir, output_data_dir, os.path.splitext(input_filename)[0])\n",
    "print(\"processing dir: [%s]\" % (processing_basedir))\n",
    "ret = create_directory(os.path.join(base_dir, data_dir, output_data_dir))\n",
    "ret = create_directory(processing_basedir)\n",
    "\n",
    "output_tables_dir = os.path.join(processing_basedir, output_extracted_tables_dir)\n",
    "print(\"tables dir: [%s]\" % (output_tables_dir))\n",
    "ret = create_directory(output_tables_dir)\n",
    "\n",
    "output_boxes_dir = os.path.join(processing_basedir, output_extracted_boxes_dir)\n",
    "print(\"boxes dir: [%s]\" % (output_boxes_dir))\n",
    "ret = create_directory(output_boxes_dir)\n",
    "\n",
    "output_letters_dir = os.path.join(processing_basedir, output_extracted_letters_dir)\n",
    "print(\"letters: [%s]\" % (output_letters_dir))\n",
    "ret = create_directory(output_letters_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found (2) tables in [sample_input_02.jpg]\n"
     ]
    }
   ],
   "source": [
    "extract_tables(img_filename, output_tables_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found (15) boxes in [0_1_sample_input_02.jpg]\n",
      "found (54) boxes in [0_0_sample_input_02.jpg]\n"
     ]
    }
   ],
   "source": [
    "table_files = read_directory_files(output_tables_dir)\n",
    "for file in table_files:\n",
    "    output_dir = os.path.join(output_boxes_dir, os.path.splitext(os.path.basename(file))[0])\n",
    "    ret = create_directory(output_dir)\n",
    "    extract_table_boxes(file, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found (3) letters in [8_3_0_0_sample_input_02.jpg]\n",
      "found (1) letters in [6_1_0_0_sample_input_02.jpg]\n",
      "found (0) letters in [5_0_0_0_sample_input_02.jpg]\n",
      "found (14) letters in [0_3_0_0_sample_input_02.jpg]\n",
      "found (3) letters in [3_2_0_0_sample_input_02.jpg]\n",
      "found (7) letters in [2_4_0_0_sample_input_02.jpg]\n",
      "found (5) letters in [5_4_0_0_sample_input_02.jpg]\n",
      "found (3) letters in [4_2_0_0_sample_input_02.jpg]\n",
      "found (1) letters in [9_1_0_0_sample_input_02.jpg]\n",
      "found (1) letters in [7_3_0_0_sample_input_02.jpg]\n",
      "found (2) letters in [2_0_0_0_sample_input_02.jpg]\n",
      "found (1) letters in [10_0_0_0_sample_input_02.jpg]\n",
      "found (3) letters in [1_1_0_0_sample_input_02.jpg]\n",
      "found (2) letters in [4_1_0_0_sample_input_02.jpg]\n",
      "found (1) letters in [7_0_0_0_sample_input_02.jpg]\n",
      "found (0) letters in [9_2_0_0_sample_input_02.jpg]\n",
      "found (3) letters in [10_3_0_0_sample_input_02.jpg]\n",
      "found (1) letters in [2_3_0_0_sample_input_02.jpg]\n",
      "found (3) letters in [1_2_0_0_sample_input_02.jpg]\n",
      "found (7) letters in [0_4_0_0_sample_input_02.jpg]\n",
      "found (1) letters in [8_4_0_0_sample_input_02.jpg]\n",
      "found (4) letters in [7_4_0_0_sample_input_02.jpg]\n",
      "found (0) letters in [6_2_0_0_sample_input_02.jpg]\n",
      "found (1) letters in [8_0_0_0_sample_input_02.jpg]\n",
      "found (1) letters in [5_3_0_0_sample_input_02.jpg]\n",
      "found (60) letters in [0_0_0_0_sample_input_02.jpg]\n",
      "found (4) letters in [3_1_0_0_sample_input_02.jpg]\n",
      "found (2) letters in [1_0_0_0_sample_input_02.jpg]\n",
      "found (0) letters in [10_1_0_0_sample_input_02.jpg]\n",
      "found (4) letters in [2_1_0_0_sample_input_02.jpg]\n",
      "found (1) letters in [9_0_0_0_sample_input_02.jpg]\n",
      "found (0) letters in [7_2_0_0_sample_input_02.jpg]\n",
      "found (2) letters in [4_3_0_0_sample_input_02.jpg]\n",
      "found (3) letters in [6_4_0_0_sample_input_02.jpg]\n",
      "found (1) letters in [9_4_0_0_sample_input_02.jpg]\n",
      "found (1) letters in [1_4_0_0_sample_input_02.jpg]\n",
      "found (1) letters in [3_3_0_0_sample_input_02.jpg]\n",
      "found (10) letters in [0_2_0_0_sample_input_02.jpg]\n",
      "found (0) letters in [5_1_0_0_sample_input_02.jpg]\n",
      "found (1) letters in [8_2_0_0_sample_input_02.jpg]\n",
      "found (0) letters in [6_0_0_0_sample_input_02.jpg]\n",
      "found (3) letters in [3_0_0_0_sample_input_02.jpg]\n",
      "found (11) letters in [0_1_0_0_sample_input_02.jpg]\n",
      "found (1) letters in [5_2_0_0_sample_input_02.jpg]\n",
      "found (2) letters in [6_3_0_0_sample_input_02.jpg]\n",
      "found (0) letters in [8_1_0_0_sample_input_02.jpg]\n",
      "found (5) letters in [4_4_0_0_sample_input_02.jpg]\n",
      "found (6) letters in [3_4_0_0_sample_input_02.jpg]\n",
      "found (5) letters in [1_3_0_0_sample_input_02.jpg]\n",
      "found (3) letters in [2_2_0_0_sample_input_02.jpg]\n",
      "found (0) letters in [10_2_0_0_sample_input_02.jpg]\n",
      "found (1) letters in [7_1_0_0_sample_input_02.jpg]\n",
      "found (2) letters in [9_3_0_0_sample_input_02.jpg]\n",
      "found (2) letters in [4_0_0_0_sample_input_02.jpg]\n",
      "found (20) letters in [0_3_0_1_sample_input_02.jpg]\n",
      "found (14) letters in [2_4_0_1_sample_input_02.jpg]\n",
      "found (6) letters in [2_0_0_1_sample_input_02.jpg]\n",
      "found (11) letters in [1_1_0_1_sample_input_02.jpg]\n",
      "found (5) letters in [2_3_0_1_sample_input_02.jpg]\n",
      "found (13) letters in [1_2_0_1_sample_input_02.jpg]\n",
      "found (13) letters in [0_4_0_1_sample_input_02.jpg]\n",
      "found (0) letters in [0_0_0_1_sample_input_02.jpg]\n",
      "found (2) letters in [1_0_0_1_sample_input_02.jpg]\n",
      "found (5) letters in [2_1_0_1_sample_input_02.jpg]\n",
      "found (11) letters in [1_4_0_1_sample_input_02.jpg]\n",
      "found (12) letters in [0_2_0_1_sample_input_02.jpg]\n",
      "found (4) letters in [0_1_0_1_sample_input_02.jpg]\n",
      "found (13) letters in [1_3_0_1_sample_input_02.jpg]\n",
      "found (7) letters in [2_2_0_1_sample_input_02.jpg]\n"
     ]
    }
   ],
   "source": [
    "boxes_dirs = get_subdirectories(output_boxes_dir)\n",
    "for boxes_dir in boxes_dirs:\n",
    "    boxes_files = read_directory_files(boxes_dir)\n",
    "    output_dir1 = os.path.join(output_letters_dir, os.path.basename(boxes_dir))\n",
    "    ret         = create_directory(output_dir1)\n",
    "    \n",
    "    for file in boxes_files:\n",
    "        output_dir = os.path.join(output_dir1, os.path.splitext(os.path.basename(file))[0])\n",
    "        ret = create_directory(output_dir)\n",
    "        extract_box_letters(file, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cv3]",
   "language": "python",
   "name": "conda-env-cv3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
