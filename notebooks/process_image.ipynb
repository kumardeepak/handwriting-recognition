{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import uuid\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure you have \"data\" directory in parallel to \"notebooks\". Create \"input\" directory under\n",
    "# \"data\" directory and copy sample image file.\n",
    "# application creates \"output\" programmatically.\n",
    "# ----+/notebooks\n",
    "# ----+/data\n",
    "# ----------+/input\n",
    "\n",
    "base_dir                   = '/Users/kd/Workspace/python/github/handwriting-recognition'\n",
    "data_dir                   = 'data'\n",
    "input_data_dir             = 'input'\n",
    "output_data_dir            = 'output'\n",
    "\n",
    "output_cropped_data_dir        = 'cropped'\n",
    "output_extracted_data_dir      = 'extracted'\n",
    "output_letter_cropped_data_dir = 'letter-cropped'\n",
    "input_filename                 = 'sample_input_02.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function\n",
    "def create_directory(path):\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "        return True\n",
    "    except FileExistsError as fe_error:\n",
    "        return True\n",
    "    except OSError as error:\n",
    "        print(error)\n",
    "    return False\n",
    "\n",
    "# read file directory\n",
    "def read_directory(path, pattern='*'):\n",
    "    files = [f for f in glob.glob(os.path.join(path, pattern))]\n",
    "    return files\n",
    "\n",
    "def show_img(img):\n",
    "    plt.axis('off')\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify number of tables present on the given image file\n",
    "def get_table_bounding_boxes(threshold, image):\n",
    "    kernel          = np.ones((3,3), 'uint8')\n",
    "    par_img         = cv2.dilate(threshold, kernel, iterations=2)\n",
    "    _, contours, _  = cv2.findContours(par_img.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "# save table images separately\n",
    "def get_relevant_images(img, contours, allowed_area=50000):\n",
    "    images = []\n",
    "    for cnt in contours:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        if (w*h) > allowed_area:\n",
    "            crop_img = img[y:y+h, x:x+w]\n",
    "            images.append(crop_img)\n",
    "    return images\n",
    "\n",
    "\n",
    "def extract_save_tables(filepath, extraction_path):\n",
    "    image           = cv2.imread(filepath)\n",
    "    gray            = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, threshold  = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    \n",
    "    contours        = get_table_bounding_boxes(threshold, image)\n",
    "    images          = get_relevant_images(image, contours)\n",
    "    print(\"found (%d) image of interest in the given filepath (%s)\"%(len(images), filepath))\n",
    "    for index, image in enumerate(images):\n",
    "        temp_filepath = os.path.join(extraction_path, \"extract_\" + str(index) + \".jpg\")\n",
    "        print(\"saving table at (%s)\"%(temp_filepath))\n",
    "        cv2.imwrite(temp_filepath, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect horizontal and vertical lines in the cropped images and extract boxes\n",
    "def smoothen_out_image(image):\n",
    "    edges  = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 3, -2)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    edges  = cv2.dilate(edges, kernel)\n",
    "    smooth = np.copy(image)\n",
    "    smooth = cv2.blur(smooth, (2, 2))\n",
    "    (rows, cols) = np.where(edges != 0)\n",
    "    image[rows, cols] = smooth[rows, cols]\n",
    "    return image\n",
    "\n",
    "def combine_image(vertical_img, horizontal_img):\n",
    "    alpha  = 0.5\n",
    "    beta   = 1.0 - alpha\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    # This function helps to add two image with specific weight parameter to get a third image as summation of two image.\n",
    "    img_final = cv2.addWeighted(vertical_img, alpha, horizontal_img, beta, 0.0)\n",
    "    img_final = cv2.erode(~img_final, kernel, iterations=2)\n",
    "    (thresh, img_final) = cv2.threshold(img_final, 128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    return img_final\n",
    "\n",
    "def extract_boxes_from_image(filepath):\n",
    "    src_img      = cv2.imread(filepath, cv2.IMREAD_COLOR)\n",
    "    gray_img     = src_img\n",
    "    if len(src_img.shape) == 3:\n",
    "        gray_img = cv2.cvtColor(src_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    gray_img = cv2.bitwise_not(gray_img)\n",
    "    bw_img   = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15, -2)\n",
    "    \n",
    "    horizontal_img = np.copy(bw_img)\n",
    "    vertical_img   = np.copy(bw_img)\n",
    "    \n",
    "    cols = horizontal_img.shape[1]\n",
    "    horizontal_size = cols // 30\n",
    "    horizontalStructure = cv2.getStructuringElement(cv2.MORPH_RECT, (horizontal_size, 1))\n",
    "    horizontal_img = cv2.erode(horizontal_img, horizontalStructure)\n",
    "    horizontal_img = cv2.dilate(horizontal_img, horizontalStructure)\n",
    "    \n",
    "    rows = vertical_img.shape[0]\n",
    "    vertical_size = rows // 30\n",
    "    verticalStructure = cv2.getStructuringElement(cv2.MORPH_RECT, (1, vertical_size))\n",
    "    vertical_img = cv2.erode(vertical_img, verticalStructure)\n",
    "    vertical_img = cv2.dilate(vertical_img, verticalStructure)\n",
    "    \n",
    "    horizontal_img = smoothen_out_image(horizontal_img)\n",
    "    vertical_img   = smoothen_out_image(vertical_img)\n",
    "    \n",
    "    img_final      = combine_image(vertical_img, horizontal_img)\n",
    "    return src_img, img_final\n",
    "\n",
    "def sort_contours(cnts, method=\"left-to-right\"):\n",
    "    # initialize the reverse flag and sort index\n",
    "    reverse = False\n",
    "    i = 0\n",
    "\n",
    "    # handle if we need to sort in reverse\n",
    "    if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "        reverse = True\n",
    "\n",
    "    # handle if we are sorting against the y-coordinate rather than\n",
    "    # the x-coordinate of the bounding box\n",
    "    if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "        i = 1\n",
    "\n",
    "    # construct the list of bounding boxes and sort them from top to\n",
    "    # bottom\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "        key=lambda b:b[1][i], reverse=reverse))\n",
    "\n",
    "    # return the list of sorted contours and bounding boxes\n",
    "    return (cnts, boundingBoxes)\n",
    "\n",
    "\n",
    "# resize the image by joining the image\n",
    "def resize_image(img, size=(64,64)):\n",
    "    h, w = img.shape[:2]\n",
    "    if h == w: \n",
    "        return cv2.resize(img, size, cv2.INTER_AREA)\n",
    "    dif = h if h > w else w\n",
    "    interpolation = cv2.INTER_AREA if dif > (size[0]+size[1])//2 else cv2.INTER_CUBIC\n",
    "    x_pos = (dif - w)//2\n",
    "    y_pos = (dif - h)//2\n",
    "\n",
    "    if len(img.shape) == 2:\n",
    "        mask = np.zeros((dif, dif), dtype=img.dtype)\n",
    "        mask[y_pos:y_pos+h, x_pos:x_pos+w] = img[:h, :w]\n",
    "    else:\n",
    "        mask = np.zeros((dif, dif, c), dtype=img.dtype)\n",
    "        mask[y_pos:y_pos+h, x_pos:x_pos+w, :] = img[:h, :w, :]\n",
    "\n",
    "    return cv2.resize(mask, size, interpolation)\n",
    "\n",
    "# let's extract characters from the detected table boxes\n",
    "def extract_individual_characters(filepath, output_dir):\n",
    "#     output_dir = os.path.join(os.path.dirname(filepath), 'cropped')\n",
    "#     ret = create_directory(output_dir)\n",
    "    \n",
    "#     file_output_cropped_dir = os.path.join(output_dir, os.path.splitext(os.path.basename(filepath))[0])\n",
    "#     ret = create_directory(file_output_cropped_dir)\n",
    "    \n",
    "    gray_img = cv2.imread(filepath, 0)\n",
    "    # gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    gray_img = cv2.bitwise_not(gray_img)\n",
    "    #bw_img   = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15, -2)\n",
    "    bw_img   = cv2.adaptiveThreshold(gray_img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,15,-2)\n",
    "    # find contours and get the external one\n",
    "    _, contours, hier = cv2.findContours(bw_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Sort all the contours by top to bottom.\n",
    "    (contours, boundingBoxes) = sort_contours(contours, method='left-to-right')\n",
    "    \n",
    "    print(\"processing contours for filename: %s\"%(filepath))\n",
    "    \n",
    "    cont_ind = 0\n",
    "    for index, contour in enumerate(contours):\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if h > 5 and w < 50:\n",
    "            filename = os.path.join(output_dir, str(int(cont_ind/len(contours)))+\"_\"+str(int(cont_ind%len(contours)))+\"_\"+os.path.basename(filepath))\n",
    "            print(filename)\n",
    "            crop_img = gray_img[y:y+h, x:x+w]\n",
    "            crop_img = resize_image(crop_img)\n",
    "            cv2.imwrite(filename, crop_img)\n",
    "            cont_ind = cont_ind + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input filename : [/Users/kd/Workspace/python/github/handwriting-recognition/data/input/sample_input_02.jpg]\n",
      "output working directory: [/Users/kd/Workspace/python/github/handwriting-recognition/data/output/sample_input_02]\n",
      "output cropped directory: [/Users/kd/Workspace/python/github/handwriting-recognition/data/output/sample_input_02/cropped]\n",
      "output extracted directory: [/Users/kd/Workspace/python/github/handwriting-recognition/data/output/sample_input_02/extracted]\n",
      "output cropped directory: [/Users/kd/Workspace/python/github/handwriting-recognition/data/output/sample_input_02/letter-cropped]\n"
     ]
    }
   ],
   "source": [
    "# program initialization \n",
    "img_filename    = os.path.join(base_dir, data_dir, input_data_dir, input_filename)\n",
    "print(\"input filename : [%s]\"%(img_filename))\n",
    "\n",
    "output_basedir  = os.path.join(base_dir, data_dir, output_data_dir, os.path.splitext(input_filename)[0])\n",
    "print(\"output working directory: [%s]\"%(output_basedir))\n",
    "ret = create_directory(os.path.join(base_dir, data_dir, output_data_dir))\n",
    "ret = create_directory(output_basedir)\n",
    "\n",
    "output_cropped_dir = os.path.join(output_basedir, output_cropped_data_dir)\n",
    "print(\"output cropped directory: [%s]\"%(output_cropped_dir))\n",
    "ret = create_directory(output_cropped_dir)\n",
    "\n",
    "output_extracted_dir = os.path.join(output_basedir, output_extracted_data_dir)\n",
    "print(\"output extracted directory: [%s]\"%(output_extracted_dir))\n",
    "ret = create_directory(output_extracted_dir)\n",
    "\n",
    "output_letter_cropped_dir = os.path.join(output_basedir, output_letter_cropped_data_dir)\n",
    "print(\"output cropped directory: [%s]\"%(output_letter_cropped_dir))\n",
    "ret = create_directory(output_letter_cropped_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tables for filename: [/Users/kd/Workspace/python/github/handwriting-recognition/data/input/sample_input_02.jpg]\n"
     ]
    }
   ],
   "source": [
    "# let's extract all the tables present and save them individually\n",
    "image, image_processed = extract_boxes_from_image(img_filename)\n",
    "_, contours, hierarchy = cv2.findContours(image_processed, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "(contours, boundingBoxes) = sort_contours(contours, method='top-to-bottom')\n",
    "print(\"extracting tables for filename: [%s]\" % (img_filename))\n",
    "\n",
    "for index, contour in enumerate(contours):\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    if (w*h > 300000) and (w*h < 800000):\n",
    "        filename = os.path.join(output_extracted_dir, \"table_\" + str(index)+ \"_\" + os.path.basename(img_filename))\n",
    "        crop_img = image[y:y+h, x:x+w]\n",
    "        cv2.imwrite(filename, crop_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing contours for filename: /Users/kd/Workspace/python/github/handwriting-recognition/data/output/sample_input_02/extracted/table_1_sample_input_02.jpg\n",
      "processing contours for filename: /Users/kd/Workspace/python/github/handwriting-recognition/data/output/sample_input_02/extracted/table_53_sample_input_02.jpg\n"
     ]
    }
   ],
   "source": [
    "extracted_files = read_directory(output_extracted_dir)\n",
    "\n",
    "for filepath in extracted_files:\n",
    "    file_output_cropped_dir = output_cropped_dir\n",
    "    ret = create_directory(file_output_cropped_dir)\n",
    "\n",
    "    image, image_processed = extract_boxes_from_image(filepath)\n",
    "    # Find contours for image, which will detect all the boxes\n",
    "    _, contours, hierarchy = cv2.findContours(image_processed, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Sort all the contours by top to bottom.\n",
    "    (contours, boundingBoxes) = sort_contours(contours, method='top-to-bottom')\n",
    "    print(\"processing contours for filename: %s\"%(filepath))\n",
    "    cont_ind = 0\n",
    "    for index, contour in enumerate(contours):\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if (w > 80 and h > 20) and (w*h < 100000):\n",
    "            filename = os.path.join(file_output_cropped_dir, str(int(cont_ind/5))+\"_\"+str(int(cont_ind%5))+\"_\"+os.path.basename(filepath))\n",
    "            crop_img = image[y:y+h, x:x+w]\n",
    "            cv2.imwrite(filename, crop_img)\n",
    "            cont_ind = cont_ind + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path1 = '/Users/kd/Workspace/python/github/handwriting-recognition/data/output/sample_input_02/cropped/sample_input_02/13_0_3_table_53_sample_input_02.jpg'\n",
    "# extract_individual_characters(path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing contours for filename: /Users/kd/Workspace/python/github/handwriting-recognition/data/output/sample_input_02/cropped/6_0_table_1_sample_input_02.jpg\n",
      "processing contours for filename: /Users/kd/Workspace/python/github/handwriting-recognition/data/output/sample_input_02/cropped/7_1_table_1_sample_input_02.jpg\n",
      "/Users/kd/Workspace/python/github/handwriting-recognition/data/output/sample_input_02/letter-cropped/7_1_table_1_sample_input_02/0_0_7_1_table_1_sample_input_02.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "extracted_cropped_files = read_directory(output_cropped_dir)\n",
    "for filepath in extracted_cropped_files:\n",
    "    file_output_cropped_dir = os.path.join(output_letter_cropped_dir, os.path.splitext(os.path.basename(filepath))[0])\n",
    "    ret = create_directory(file_output_cropped_dir)\n",
    "    extract_individual_characters(filepath, file_output_cropped_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cv3]",
   "language": "python",
   "name": "conda-env-cv3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
